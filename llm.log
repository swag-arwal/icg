2025-11-07 22:56:34,497 - __main__ - INFO - ============================================================
2025-11-07 22:56:34,498 - __main__ - INFO - Starting LLM RAG Pipeline
2025-11-07 22:56:34,498 - __main__ - INFO - ============================================================
2025-11-07 22:56:34,498 - __main__ - INFO - Processing 6 files
2025-11-07 22:56:34,498 - __main__ - INFO - Step 1: Loading tables from 6 files...
2025-11-07 22:56:34,936 - __main__ - INFO - Loaded 6 tables
2025-11-07 22:56:34,936 - __main__ - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 22:56:34,961 - __main__ - INFO - Created 150 chunks
2025-11-07 22:56:34,963 - __main__ - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 22:56:34,963 - __main__ - INFO - Files have changed or cache not found, will regenerate embeddings
2025-11-07 22:56:34,963 - __main__ - INFO - Generating embeddings using model: all-MiniLM-L6-v2
2025-11-07 22:56:34,965 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 22:56:34,966 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 22:56:41,736 - __main__ - INFO - Encoding 150 chunks...
2025-11-07 22:56:55,710 - __main__ - INFO - Saving embeddings and index to cache...
2025-11-07 22:56:55,712 - __main__ - INFO - FAISS index saved to cache\faiss_index.bin
2025-11-07 22:56:55,714 - __main__ - INFO - Embeddings saved to cache\embeddings.npy
2025-11-07 22:56:55,720 - __main__ - INFO - Chunks saved to cache\chunks.pkl
2025-11-07 22:56:55,721 - __main__ - INFO - Model name saved: all-MiniLM-L6-v2
2025-11-07 22:56:55,749 - __main__ - INFO - Cache metadata saved successfully
2025-11-07 22:56:55,756 - __main__ - INFO - Step 4: Retrieving top 3 results for: 'what percentage of children are enrolled in government primary schools in india in 2024'
2025-11-07 22:56:55,855 - __main__ - INFO - Retrieved 3 chunks:
2025-11-07 22:56:55,862 - __main__ - INFO - Step 5: Generating final LLM prompt...
2025-11-07 22:56:55,864 - __main__ - INFO - Calling LLM for answer...
2025-11-07 22:56:55,866 - __main__ - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 22:56:57,340 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 22:56:59,369 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 22:56:59,430 - __main__ - INFO - 
============================================================
2025-11-07 22:56:59,459 - __main__ - INFO - FINAL RESULTS
2025-11-07 22:56:59,465 - __main__ - INFO - ============================================================
2025-11-07 22:56:59,480 - __main__ - INFO - Pipeline completed successfully
2025-11-07 22:58:45,055 - __main__ - INFO - ============================================================
2025-11-07 22:58:45,056 - __main__ - INFO - Starting LLM RAG Pipeline
2025-11-07 22:58:45,056 - __main__ - INFO - ============================================================
2025-11-07 22:58:45,056 - __main__ - INFO - Processing 6 files
2025-11-07 22:58:45,056 - __main__ - INFO - Step 1: Loading tables from 6 files...
2025-11-07 22:58:45,101 - __main__ - INFO - Loaded 6 tables
2025-11-07 22:58:45,101 - __main__ - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 22:58:45,205 - __main__ - INFO - Created 150 chunks
2025-11-07 22:58:45,206 - __main__ - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 22:58:45,287 - __main__ - INFO - All files unchanged, can use cache
2025-11-07 22:58:45,287 - __main__ - INFO - Loading embeddings and index from cache...
2025-11-07 22:58:45,287 - __main__ - INFO - Loading embeddings and index from cache...
2025-11-07 22:58:45,319 - __main__ - INFO - FAISS index loaded: 150 vectors
2025-11-07 22:58:45,353 - __main__ - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 22:58:45,547 - __main__ - INFO - Chunks loaded: 150 chunks
2025-11-07 22:58:45,574 - __main__ - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 22:58:45,596 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 22:58:45,600 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 22:58:51,065 - __main__ - INFO - Step 4: Retrieving top 3 results for: 'what percentage of children are enrolled in government primary schools in india in 2024'
2025-11-07 22:58:51,343 - __main__ - INFO - Retrieved 3 chunks:
2025-11-07 22:58:51,629 - __main__ - INFO - Step 5: Generating final LLM prompt...
2025-11-07 22:58:51,645 - __main__ - INFO - Calling LLM for answer...
2025-11-07 22:58:51,658 - __main__ - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 22:58:53,320 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 22:58:56,816 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 22:58:56,837 - __main__ - INFO - 
============================================================
2025-11-07 22:58:56,838 - __main__ - INFO - FINAL RESULTS
2025-11-07 22:58:56,838 - __main__ - INFO - ============================================================
2025-11-07 22:58:56,844 - __main__ - INFO - Pipeline completed successfully
2025-11-07 23:08:18,242 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:08:18,580 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:08:18,659 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:08:18,695 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:08:18,695 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:08:18,698 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:08:18,707 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:08:18,709 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:08:18,713 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:08:18,716 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:08:18,755 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:08:18,759 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:08:59,680 - llm - INFO - Step 4: Retrieving top 3 results for: 'so what canyou'
2025-11-07 23:09:00,112 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:09:00,288 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:09:00,291 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:09:00,858 - llm - INFO - Step 4: Retrieving top 3 results for: 'so what canyou'
2025-11-07 23:09:02,945 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:09:03,818 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:09:03,831 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:09:07,835 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:09:08,348 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:09:09,350 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:09:09,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:09:44,412 - llm - INFO - Step 4: Retrieving top 3 results for: 'what I meant was, how's that stats bitch?'
2025-11-07 23:09:44,547 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:09:44,604 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:09:44,604 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:09:47,601 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:09:49,501 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:22:22,836 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:22:23,109 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:22:23,163 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:22:23,176 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:22:23,177 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:22:23,177 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:22:23,183 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:22:23,184 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:22:23,187 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:22:23,189 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:22:23,207 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:22:23,208 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:23:05,442 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-07 23:23:06,974 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:23:07,063 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:23:07,063 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:23:10,670 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:23:12,405 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:23:58,554 - llm - INFO - Step 4: Retrieving top 3 results for: 'heyhe'
2025-11-07 23:23:58,665 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:23:58,722 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:23:58,725 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:24:02,837 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:24:04,533 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:25:05,367 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:25:05,502 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:25:05,543 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:25:05,556 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:25:05,556 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:25:05,557 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:25:05,559 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:25:05,559 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:25:05,562 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:25:05,563 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:25:05,576 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:25:05,576 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:31:58,416 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:31:58,593 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:31:58,671 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:31:58,689 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:31:58,689 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:31:58,691 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:31:58,692 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:31:58,694 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:31:58,702 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:31:58,704 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:31:58,745 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:31:58,746 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:32:14,815 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-07 23:32:15,043 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:32:15,065 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:32:15,066 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:32:17,750 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:32:19,587 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:32:40,604 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-07 23:32:40,844 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:32:40,864 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:32:40,865 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:32:43,614 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:32:44,744 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-11-07 23:32:44,748 - llm - ERROR - Error getting LLM answer: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}
2025-11-07 23:33:16,392 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-07 23:33:16,589 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:33:16,626 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:33:16,628 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:33:19,479 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:33:22,402 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:34:56,541 - llm - INFO - Step 4: Retrieving top 3 results for: 'what's up with punjab?'
2025-11-07 23:34:56,685 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:34:56,725 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:34:56,725 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:34:59,894 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:35:09,727 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:47:29,066 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:47:29,186 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:47:29,279 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:47:29,302 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:47:29,302 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:47:29,304 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:47:29,313 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:47:29,317 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:47:29,322 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:47:29,327 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:47:29,374 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:47:29,378 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:48:01,152 - llm - INFO - Step 4: Retrieving top 3 results for: 'hey'
2025-11-07 23:48:02,887 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:48:03,070 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:48:03,071 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:48:05,985 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:48:07,934 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-07 23:53:40,760 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-07 23:53:41,242 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-07 23:53:41,372 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-07 23:53:41,422 - llm - INFO - All files unchanged, can use cache
2025-11-07 23:53:41,423 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:53:41,424 - llm - INFO - Loading embeddings and index from cache...
2025-11-07 23:53:41,426 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-07 23:53:41,431 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-07 23:53:41,439 - llm - INFO - Chunks loaded: 150 chunks
2025-11-07 23:53:41,440 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-07 23:53:41,523 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-07 23:53:41,526 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-07 23:54:27,380 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-07 23:54:27,522 - llm - INFO - Retrieved 3 chunks:
2025-11-07 23:54:27,548 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-07 23:54:27,550 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-07 23:54:30,360 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-07 23:54:32,379 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-08 00:01:27,710 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-08 00:01:27,876 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-08 00:01:27,966 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-08 00:01:27,993 - llm - INFO - All files unchanged, can use cache
2025-11-08 00:01:28,043 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:01:28,045 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:01:28,058 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-08 00:01:28,089 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-08 00:01:28,107 - llm - INFO - Chunks loaded: 150 chunks
2025-11-08 00:01:28,120 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-08 00:01:28,174 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-08 00:01:28,176 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-08 00:05:04,563 - llm - INFO - Step 4: Retrieving top 3 results for: 'hi'
2025-11-08 00:05:04,661 - llm - INFO - Retrieved 3 chunks:
2025-11-08 00:05:04,671 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-08 00:05:04,672 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-08 00:05:07,027 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-08 00:05:09,115 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-08 00:06:49,682 - llm - INFO - Step 4: Retrieving top 3 results for: 'hey'
2025-11-08 00:06:49,868 - llm - INFO - Retrieved 3 chunks:
2025-11-08 00:06:49,883 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-08 00:06:49,883 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-08 00:06:52,491 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-08 00:06:54,202 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-08 00:08:08,670 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-08 00:08:09,189 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-08 00:08:09,265 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-08 00:08:09,282 - llm - INFO - All files unchanged, can use cache
2025-11-08 00:08:09,283 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:08:09,287 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:08:09,288 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-08 00:08:09,292 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-08 00:08:09,298 - llm - INFO - Chunks loaded: 150 chunks
2025-11-08 00:08:09,303 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-08 00:08:09,323 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-08 00:08:09,324 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-08 00:52:37,109 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-08 00:52:37,201 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-08 00:52:37,242 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-08 00:52:37,279 - llm - INFO - All files unchanged, can use cache
2025-11-08 00:52:37,280 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:52:37,280 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 00:52:37,321 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-08 00:52:37,343 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-08 00:52:37,392 - llm - INFO - Chunks loaded: 150 chunks
2025-11-08 00:52:37,396 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-08 00:52:37,412 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-08 00:52:37,413 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-08 00:53:01,667 - llm - INFO - Step 4: Retrieving top 3 results for: 'hey bitch?'
2025-11-08 00:53:02,009 - llm - INFO - Retrieved 3 chunks:
2025-11-08 00:53:02,027 - llm - INFO - Step 5: Generating final LLM prompt...
2025-11-08 00:53:02,028 - llm - INFO - Step 6: Getting answer from LLM (model: gemini-2.0-flash)...
2025-11-08 00:53:03,775 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-11-08 00:53:05,291 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-08 01:09:25,305 - llm - INFO - Step 1: Loading tables from 6 files...
2025-11-08 01:09:25,502 - llm - INFO - Step 2: Creating row-based chunks with metadata...
2025-11-08 01:09:25,587 - llm - INFO - Step 3: Embedding chunks and building FAISS index...
2025-11-08 01:09:25,601 - llm - INFO - All files unchanged, can use cache
2025-11-08 01:09:25,601 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 01:09:25,601 - llm - INFO - Loading embeddings and index from cache...
2025-11-08 01:09:25,608 - llm - INFO - FAISS index loaded: 150 vectors
2025-11-08 01:09:25,613 - llm - INFO - Embeddings loaded: shape (150, 384)
2025-11-08 01:09:25,620 - llm - INFO - Chunks loaded: 150 chunks
2025-11-08 01:09:25,622 - llm - INFO - Model name: all-MiniLM-L6-v2
2025-11-08 01:09:25,691 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-11-08 01:09:25,692 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
